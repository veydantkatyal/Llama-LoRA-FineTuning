{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veydantkatyal/Llama-LoRA-FineTuning/blob/main/Fine_Tune_Llama_3_2_1B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwLC_-Kr5F47"
      },
      "source": [
        "# Fine-tuning Llama-3.2 1B for Dialogue Summarization\n",
        "\n",
        "This notebook demonstrates how to fine-tune Meta's Llama-3.2 1B language model for a specific task: summarizing dialogues. We'll use modern techniques like LoRA (Low-Rank Adaptation) and quantization to make this process efficient and accessible even with limited computational resources.\n",
        "\n",
        "## What we'll cover:\n",
        "1. Setting up the required libraries\n",
        "2. Loading and preparing the model\n",
        "3. Processing our dataset\n",
        "4. Configuring the fine-tuning process\n",
        "5. Training the model\n",
        "\n",
        "Note: This notebook assumes you have access to a GPU. We'll be using techniques to minimize memory usage while maintaining performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIvlYPZO5P0B"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, we'll install the necessary libraries:\n",
        "- `bitsandbytes`: For model quantization (reducing model size)\n",
        "- `transformers`: Hugging Face's library for working with language models\n",
        "- `peft`: For efficient fine-tuning using LoRA\n",
        "- `accelerate`: For optimized model training\n",
        "- `datasets`: For handling our training data\n",
        "- `trl`: For supervised fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqgNRtye9gGB",
        "outputId": "1bd99083-e19f-43bd-ce98-5867f6ac79d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes transformers peft accelerate datasets trl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd8XvjAE5ULP"
      },
      "source": [
        "## Importing Required Libraries\n",
        "\n",
        "We import the necessary modules for our task. Each has a specific purpose:\n",
        "- `datasets`: To load and process our training data\n",
        "- `AutoModelForCausalLM`: To load our pre-trained language model\n",
        "- `BitsAndBytesConfig`: For model quantization\n",
        "- `TrainingArguments`: To configure training parameters\n",
        "- `SFTTrainer`: For supervised fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSkxCaYf9fVa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    set_seed\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from functools import partial\n",
        "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUxXeILu5cFs"
      },
      "source": [
        "We'll set CUDA (GPU) as our default device. This ensures our model training will use GPU acceleration instead of CPU, making it much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ4JYKt8tZda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c034126-a375-4547-f740-af5d607a2d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "CUDA device name: Tesla T4\n",
            "Total memory: 15.83 GB\n",
            "Memory allocated: 0.00 GB\n",
            "Memory reserved: 0.00 GB\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    device_index = torch.cuda.current_device()\n",
        "    device_name = torch.cuda.get_device_name(device_index)\n",
        "    total_mem = torch.cuda.get_device_properties(device_index).total_memory / 1e9  # bytes to GB\n",
        "    allocated_mem = torch.cuda.memory_allocated(device_index) / 1e9\n",
        "    reserved_mem = torch.cuda.memory_reserved(device_index) / 1e9\n",
        "\n",
        "    print(f\"CUDA device name: {device_name}\")\n",
        "    print(f\"Total memory: {total_mem:.2f} GB\")\n",
        "    print(f\"Memory allocated: {allocated_mem:.2f} GB\")\n",
        "    print(f\"Memory reserved: {reserved_mem:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8euXANM5hK0"
      },
      "source": [
        "## Loading the Dataset\n",
        "\n",
        "We're using the \"dialogsum-test\" dataset, which contains conversations and their summaries. This dataset will help us train our model to generate concise summaries of dialogues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh28cw6k9fVc"
      },
      "outputs": [],
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "dataset = load_dataset(huggingface_dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD6gAqJb5nL0"
      },
      "source": [
        "## Model Quantization Configuration\n",
        "\n",
        "Here we set up quantization parameters to reduce the model's memory footprint. We're using 4-bit quantization, which significantly reduces memory usage while maintaining most of the model's performance.\n",
        "\n",
        "Key concepts:\n",
        "- Quantization: Converting model weights to lower precision (4-bit instead of 16/32-bit)\n",
        "- `compute_dtype`: The data type used for computations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRoe4q-a9fVc"
      },
      "outputs": [],
      "source": [
        "compute_dtype = getattr(torch, \"float16\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aosK3FZ15rhB"
      },
      "source": [
        "## Loading the Base Model\n",
        "\n",
        "We're loading Meta's Llama-3.2 1B model, a relatively compact but powerful language model. We're applying our quantization configuration to make it memory-efficient.\n",
        "\n",
        "Note: The model is loaded with `trust_remote_code=True` because it contains custom code from its creators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nz5Hcgc9fVc",
        "outputId": "fcc8f68b-49be-4380-dce7-e8d5b844017c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name='meta-llama/Llama-3.2-1B-Instruct'\n",
        "device_map = {\"\": 0}\n",
        "original_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                                      device_map=device_map,\n",
        "                                                      quantization_config=bnb_config,\n",
        "                                                      trust_remote_code=True,\n",
        "                                                      use_auth_token=True)\n",
        "MAX_LENGTH = original_model.config.max_position_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E3iflCv50JV"
      },
      "source": [
        "## Setting Up the Tokenizer\n",
        "\n",
        "The tokenizer converts text into numbers that the model can process. We configure it with specific settings:\n",
        "- `padding_side=\"left\"`: Adds padding tokens at the start of sequences\n",
        "- `add_eos_token` and `add_bos_token`: Adds special tokens to mark the beginning and end of sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odjlEKLo9fVd"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name, trust_remote_code=True, padding=True, padding_side=\"left\",\n",
        "    add_eos_token=False\n",
        ")\n",
        "tokenizer.pad_token = '<|finetune_right_pad_id|>'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOdSBbY253qh"
      },
      "source": [
        "## Testing Initial Model Performance\n",
        "\n",
        "Let's test our base model before fine-tuning to see how it handles dialogue summarization. This will give us a baseline to compare against after training.\n",
        "The promopt template als includes the topic, which helps to guide the tone and type of summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl2bt99E_QhY"
      },
      "outputs": [],
      "source": [
        "PROMPT_TEMPLATE = \"\"\"\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "You are an expert on summarizing conversations considering a particular topic.\n",
        "The user request will contain the topic and the conversation\n",
        "Answer with the summary only. Do not explain your answer\n",
        "<|eot_id|>\n",
        "\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "Topic: {0}\n",
        "Conversation: {1}\n",
        "\n",
        "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "{2}\n",
        "\"\"\"\n",
        "\n",
        "def generate_response(\n",
        "    model, topic, conversation, summary='',\n",
        "    max_length=MAX_LENGTH, prompt_template=PROMPT_TEMPLATE,\n",
        "    seed=42, tokenizer=tokenizer\n",
        "):\n",
        "    set_seed(seed)\n",
        "    prompt = prompt_template.format(topic, conversation, summary)\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        return_attention_mask=True,\n",
        "        padding=True\n",
        "    ).to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode full output and prompt\n",
        "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    prompt_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
        "\n",
        "    # Get only the response part\n",
        "    response_only = full_text[len(prompt_text):].strip()\n",
        "\n",
        "    return response_only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WRzYYitkkST",
        "outputId": "54727797-c1f1-45e9-c11c-ff12e74e3b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL RESPONSE: \n",
            "Person1: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
            "Person2: I found it would be a good idea to get a check-up.\n",
            "Person1: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
            "Person2: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
            "Person1: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
            "Person2: Ok.\n",
            "Person1: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
            "Person2: Yes.\n",
            "Person1: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
            "Person2: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
            "Person1: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "HUMAN GENERATED SUMMARY: \n",
            "Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n"
          ]
        }
      ],
      "source": [
        "idx = 0\n",
        "dialogue = dataset['train'][idx]['dialogue']\n",
        "topic = dataset['train'][idx]['topic']\n",
        "summary = dataset['train'][idx]['summary']\n",
        "response = generate_response(original_model, topic, dialogue)\n",
        "print('MODEL RESPONSE: ')\n",
        "print(response)\n",
        "print('-'*100)\n",
        "print('HUMAN GENERATED SUMMARY: ')\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see there are some room to improve the response by fine tuning"
      ],
      "metadata": {
        "id": "1JWsqE_PBy1c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX5jBA6N57ff"
      },
      "source": [
        "## Preparing Data Processing Functions\n",
        "\n",
        "We define several helper functions to prepare our data:\n",
        "- `apply_prompt`: Formats our input in a consistent way\n",
        "- `process_batch`: Handles tokenization of multiple examples at once\n",
        "- `process_dataset`: Combines all processing steps and prepares the final dataset\n",
        "\n",
        "These functions ensure our data is in the right format for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP6pL_YPEpY3"
      },
      "outputs": [],
      "source": [
        "def apply_prompt(sample):\n",
        "    dialogue = sample['dialogue']\n",
        "    summary = sample['summary']\n",
        "    topic = sample['topic']\n",
        "\n",
        "    sample['text'] = PROMPT_TEMPLATE.format(topic, dialogue, summary)\n",
        "    sample['text'] += tokenizer.eos_token\n",
        "    return sample\n",
        "\n",
        "def process_batch(batch, tokenizer, max_length):\n",
        "    return tokenizer(batch['text'])\n",
        "\n",
        "def process_dataset(dataset, tokenizer, max_length=MAX_LENGTH, seed=42):\n",
        "    dataset = dataset.map(apply_prompt)\n",
        "    proc_fn = partial(process_batch, max_length=max_length, tokenizer=tokenizer)\n",
        "\n",
        "    # Generated input ids\n",
        "    dataset = dataset.map(\n",
        "        proc_fn,\n",
        "        batched=True,\n",
        "        remove_columns=['id', 'topic', 'dialogue', 'summary'],\n",
        "    )\n",
        "\n",
        "    # filter samples larger than max_length\n",
        "    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
        "\n",
        "    # Shuffle\n",
        "    dataset = dataset.shuffle(seed=seed)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "49f395c0bd994ad393490b3e13e214a3",
            "8ea44d3f0fd14c23961b41e423ce8b88",
            "9957737a36e74e73bd55cbbc82bd5bf1",
            "d4ee39c8e3734784b94bbe52f15693bf",
            "48f2849f8b3c45d7b045b6f2e3ad61cf",
            "e1920ee83f5b4497b7924e85070ce844",
            "f13e1c19bc6342efab3224aa968094aa",
            "4dfda9a9e87147c380a7d2b5123ad8de",
            "c4005c16581a4e488083da2fd76c505f",
            "6901d4c7a20449419a2b85ea90a55adb",
            "0c82273dab134d19b54e0c8c405b95cd",
            "c5c24a221f0f4efc81b9b1d2636757c5",
            "f54216828bf146eb8a2172abe1f04948",
            "c05cd5d009944de6a8780d03cfadb07f",
            "b896b96c80814291bf68d6ff3d9ff868",
            "a9cda1616eea43f0b74b8822b204a4ff",
            "ea00e87172f44933905d55641db8ad5d",
            "869f76dadb824935b398476dc1220f3f",
            "06cfb77ea21e4383a5c824ee1ff188ff",
            "1dbf2a448a2a4782b0f699eab1b3986c",
            "f6ddc027a6d6488784c948a14d7412fc",
            "5e8745e5810441209035aa729bd44834",
            "c4ad4041f3494c27beb7452ab53a6349",
            "a17520f1b5eb4ed5a18d3684d28ed97c",
            "86ac97c7f35a4788b0d7dddec4e388ce",
            "d9b24cde5c48464f96e698c6b2f85d0f",
            "257814a1cce04e81ab3e444e25f520b9",
            "a3f2c3e510fe4c6184157ea4806cbcfc",
            "1645cc82fb1b4d7ebd1d8f00261130a3",
            "9587b743e6f44f038495630313b95b45",
            "781575583570456b8704d12b7ed0d3cb",
            "f1a6003cce5a4771bea9d6e4345b6007",
            "ee34f65022f640ee8388799ff495cf44",
            "102703cf296d47368bd363184fa8c114",
            "c183b4120d6446c48f627eb1ac5a1bfc",
            "5b841a3531744515b0006f832f0a1b4e",
            "832af0bd97e14215a081efcdd44e4d8d",
            "80a950bab2ae44ea868d546ab2bcfd39",
            "aca9b61c5e48482abfe86b3b76da1128",
            "25e87e1e7f3646f2a70e109d296a69e7",
            "f52da043ae654ea4a9a66772dadfdc9d",
            "cd75bdebc70646e2a3ff0f5374dd3fae",
            "2fee95b4aae344ebbe26e6b1a71712c5",
            "b4e95e63e66f4369a78d838a050eae51",
            "d0b1680927f44084a8b2c4cff8c3f240",
            "9fe9ecbb8ab640a2a69a735147b7592c",
            "6f94ce433fb747bcb26ae64f62a288b6",
            "876227fd79d64aa2a1d5da08878b6803",
            "60c0e6bb77ab414d890c4d46c0ff5e91",
            "b168cec6103a4031afbc4345225ebb0e",
            "e1cb09a6df274179adcd2d7cac55c32a",
            "eb17db9557b24f55b78a6431f2ecd157",
            "03d30b68a0e74db1952300feaeeb345e",
            "af3144822f68466cbcc47fe9d2c668b5",
            "d7c9f1b92bff4f44863b6faddba0e355",
            "0256c52c914c47c3b85459ed5dfa8525",
            "33b290ecba3c496787ec60117f0d44eb",
            "d055b8d0f98541ae9fa2c6badbd1cd44",
            "025b4ec64edd4d1eb0e3ab3e92ca2288",
            "aa1906a6271e451084c5ee23a9386d99",
            "34375b59df474fd88ec9ccd795c44cbb",
            "3c1e71a33f6d420aa5f71945f602768c",
            "fb9420136f0440fc972f3f02874a4c06",
            "395111b37e344021b92a86c6310a21bc",
            "e364bf907e99440f9505856200fdc1fc",
            "4df1101f20404d748eefb34357c00eea"
          ]
        },
        "id": "uXnKH0b2GtuD",
        "outputId": "4d9714b5-c517-453c-86bf-bc29a3226589"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49f395c0bd994ad393490b3e13e214a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5c24a221f0f4efc81b9b1d2636757c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4ad4041f3494c27beb7452ab53a6349"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "102703cf296d47368bd363184fa8c114"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0b1680927f44084a8b2c4cff8c3f240"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0256c52c914c47c3b85459ed5dfa8525"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_dataset = process_dataset(dataset['train'], tokenizer)\n",
        "eval_dataset = process_dataset(dataset['validation'], tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMWgVHQ8FAeb",
        "outputId": "7f794863-20ab-4b56-bc41-d75a92f6c67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic.\n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: get a promotion\n",
            "Conversation: #Person1#: Hello, Anna speaking!\n",
            "#Person2#: Hey, Anna, this is Jason.\n",
            "#Person1#: Jason, where have you been hiding lately? You know it's been a long time since your last call. Have you been good?\n",
            "#Person2#: Yes. How are you, Anna?\n",
            "#Person1#: I am fine. What have you been doing?\n",
            "#Person2#: Working. I've been really busy these days. I got a promotion.\n",
            "#Person1#: That's great, congratulations!\n",
            "#Person2#: Thanks. I am feeling pretty good about myself too. You know, bigger office, a raise and even an assistant.\n",
            "#Person1#: That's good. So I guess I'll have to make an appointment to see you.\n",
            "#Person2#: You are kidding.\n",
            "#Person1#: How long have you been working there?\n",
            "#Person2#: A bit over two years. This is a fast-moving company, and seniority isn't the only factor in deciding promotions.\n",
            "#Person1#: How do you like your new boss?\n",
            "#Person2#: She is very nice and open-minded.\n",
            "#Person1#: Much better than the last one, huh?\n",
            "#Person2#: Yeah. He was a real slave driver. He probably would have loved it if we were robots.\n",
            "#Person1#: Forget about him. Come over to my house tonight. Let's get drunk.\n",
            "#Person2#: Good. Tonight 8 o'clock.\n",
            "#Person1#: 8 it is. See you then.\n",
            "#Person2#: Bye.\n",
            "\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "Jason hasn't called Anna for a long time. He calls her to tell her he got a promotion and he feels good about it. Anna invites him to come over to her house tonight to get drunk.\n",
            "<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset[0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzAI6NzU5_sd"
      },
      "source": [
        "## Setting Up LoRA Configuration\n",
        "\n",
        "LoRA (Low-Rank Adaptation) is a technique that makes fine-tuning more efficient by only training a small number of additional parameters, called adapters, instead of the entire model.\n",
        "\n",
        "Key parameters:\n",
        "- `r`: The rank of the LoRA update matrices\n",
        "- `lora_alpha`: Scaling factor for LoRA updates\n",
        "- `target_modules`: Which model layers to apply LoRA to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQMWohCKHSOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afce5ca3-43e9-4ced-b8b1-45d7b308f440"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 2048)\n",
              "        (layers): ModuleList(\n",
              "          (0-15): 16 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "original_model = prepare_model_for_kbit_training(original_model)\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\n",
        "        'q_proj',\n",
        "        'k_proj',\n",
        "        'v_proj',\n",
        "        'dense'\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\n",
        "original_model.gradient_checkpointing_enable()\n",
        "\n",
        "peft_model = get_peft_model(original_model, lora_config)\n",
        "peft_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP80q-dp6HC4"
      },
      "source": [
        "## Configuring Training Parameters\n",
        "\n",
        "We set up the training process with specific parameters:\n",
        "- Small batch size to manage memory usage\n",
        "- Gradient accumulation to simulate larger batches\n",
        "- Learning rate and optimization settings\n",
        "- Evaluation and saving checkpoints during training\n",
        "\n",
        "These settings help balance training efficiency with resource constraints.\n",
        "\n",
        "We'll train only on responses, there is one workaround to fix an issue of using `DataCollatorForCompletionOnlyLM` with Llama tokenizer. You can find the reference [here](https://github.com/huggingface/trl/blob/main/docs/source/sft_trainer.md#using-token_ids-directly-for-response_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "7e71fad7b3c244bdbad476a1682370df",
            "96dea6f7ddb6423db27d4f2a5a01ed07",
            "44bb55d543074aa293b2608f3c9b81c2",
            "6fa1286cd23e47f2bc96dde9675a898b",
            "00510a27c1de4eb6bd43b8c68ad1a171",
            "85e1355703e44aeda70165fb2ac72933",
            "fcdc12bb288e4ba7988e96341d5ef869",
            "9236839a6e6946ff96d1635a7759595b",
            "b575571786e947419cc56d28f6641c71",
            "6edbeee8df7e408191c40345354f84f4",
            "684b2c26ef12460a849bfa171726ff2c",
            "75e04422412f4d16afe8b4873c9006f8",
            "6afa8be058a24a79927363e2caf9ea61",
            "34ba865dcb7a4a3ab967dc2d1ae44600",
            "5dca6fc55285466ab212a5be5850f90f",
            "229ed1f1851340ea9dc23c6c790dd29f",
            "0bf13a2fa81b42d6a04c5d64a477de78",
            "80f6601b260f4921a18a1c182aec4027",
            "d67816c9d6e3481d97a9e6e696ea064f",
            "6917bc9da67b4550a848e2c6435cfa87",
            "f6d0b0fa76c341688593b6b56067879e",
            "4584beaf5b26406ba8d32b006a9b039d"
          ]
        },
        "id": "q0GnH4e-JFES",
        "outputId": "10dc7aa1-4ef1-4995-a378-4700e1c26e29"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e71fad7b3c244bdbad476a1682370df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating eval dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75e04422412f4d16afe8b4873c9006f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
        "response_template = \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
        "response_template_with_context = f\"\\n{response_template}\"  # We added context here: \"\\n\". This is enough for this tokenizer\n",
        "response_template_ids = tokenizer.encode(response_template_with_context, add_special_tokens=False)[2:]  # Now we have it like in the dataset texts: `[2277, 29937, 4007, 22137, 29901]`\n",
        "\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir = output_dir,\n",
        "    warmup_steps=1,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=2e-4,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    logging_steps=25,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=25,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    do_eval=True,\n",
        "    gradient_checkpointing=True,\n",
        "    report_to=\"none\",\n",
        "    overwrite_output_dir = 'True',\n",
        "    group_by_length=True,\n",
        "    dataloader_pin_memory=False,\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=3,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        ")\n",
        "\n",
        "peft_model.config.use_cache = False\n",
        "\n",
        "peft_trainer = SFTTrainer(\n",
        "    model=peft_model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    args=peft_training_args,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=DataCollatorForCompletionOnlyLM(response_template_ids, tokenizer=tokenizer),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW-kPYXL69yc"
      },
      "source": [
        "## Training the adapters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that some samples are going to be larger than the context size, which will be ignored by the trainer."
      ],
      "metadata": {
        "id": "AAeZdcDZqLe-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aPg_2jUUnOuR",
        "outputId": "cc8cd84e-3f86-43b4-c535-66098d8c138b",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3115/3115 42:07, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.422900</td>\n",
              "      <td>1.186716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.045400</td>\n",
              "      <td>1.137480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.208200</td>\n",
              "      <td>1.078773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.075800</td>\n",
              "      <td>1.077345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.239400</td>\n",
              "      <td>1.051057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.941700</td>\n",
              "      <td>1.045796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.174300</td>\n",
              "      <td>1.035365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.885000</td>\n",
              "      <td>1.053288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.171700</td>\n",
              "      <td>1.023783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>1.012308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>1.109700</td>\n",
              "      <td>1.020058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.969500</td>\n",
              "      <td>1.014291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>1.122200</td>\n",
              "      <td>0.998719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.903100</td>\n",
              "      <td>1.030953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.215300</td>\n",
              "      <td>0.990906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.897900</td>\n",
              "      <td>0.998607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>1.123400</td>\n",
              "      <td>0.999860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.979900</td>\n",
              "      <td>0.999461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>1.092500</td>\n",
              "      <td>0.995266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.914400</td>\n",
              "      <td>0.981328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>1.084000</td>\n",
              "      <td>1.005560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.885900</td>\n",
              "      <td>0.989477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>1.113900</td>\n",
              "      <td>0.982959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.869000</td>\n",
              "      <td>0.977441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>1.146300</td>\n",
              "      <td>0.981885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.871000</td>\n",
              "      <td>0.979181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>1.074500</td>\n",
              "      <td>0.972906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.865100</td>\n",
              "      <td>1.004052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>1.083500</td>\n",
              "      <td>0.982710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.867400</td>\n",
              "      <td>0.972406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>1.067900</td>\n",
              "      <td>0.977872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.850500</td>\n",
              "      <td>0.964425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>1.101800</td>\n",
              "      <td>0.969571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.867200</td>\n",
              "      <td>0.965720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>1.019400</td>\n",
              "      <td>0.974724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.866100</td>\n",
              "      <td>0.951609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>1.104800</td>\n",
              "      <td>0.956238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.818000</td>\n",
              "      <td>0.953680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>1.069500</td>\n",
              "      <td>0.963476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.812900</td>\n",
              "      <td>0.968018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>1.013500</td>\n",
              "      <td>0.949172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.870400</td>\n",
              "      <td>0.946784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>1.060100</td>\n",
              "      <td>0.954064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.918200</td>\n",
              "      <td>0.953672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>1.089900</td>\n",
              "      <td>0.946331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.897200</td>\n",
              "      <td>0.948981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>1.033100</td>\n",
              "      <td>0.941889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.944377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>1.073100</td>\n",
              "      <td>0.943217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.832700</td>\n",
              "      <td>0.946879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>1.064100</td>\n",
              "      <td>0.947952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.951200</td>\n",
              "      <td>0.954566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>1.083300</td>\n",
              "      <td>0.945180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.816700</td>\n",
              "      <td>0.940282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>1.017200</td>\n",
              "      <td>0.943856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.896500</td>\n",
              "      <td>0.939600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>1.031000</td>\n",
              "      <td>0.939736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.816900</td>\n",
              "      <td>0.948067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1475</td>\n",
              "      <td>1.016100</td>\n",
              "      <td>0.941442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.869500</td>\n",
              "      <td>0.948555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1525</td>\n",
              "      <td>1.025900</td>\n",
              "      <td>0.939646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.933800</td>\n",
              "      <td>0.950144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1575</td>\n",
              "      <td>1.060700</td>\n",
              "      <td>0.931836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.867200</td>\n",
              "      <td>0.944735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>1.056500</td>\n",
              "      <td>0.928880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.879900</td>\n",
              "      <td>0.929232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1675</td>\n",
              "      <td>1.050200</td>\n",
              "      <td>0.932497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.809000</td>\n",
              "      <td>0.942791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>1.101800</td>\n",
              "      <td>0.930932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.854400</td>\n",
              "      <td>0.937342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1775</td>\n",
              "      <td>1.055400</td>\n",
              "      <td>0.933367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.867300</td>\n",
              "      <td>0.933351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1825</td>\n",
              "      <td>1.063700</td>\n",
              "      <td>0.935132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.831300</td>\n",
              "      <td>0.935693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1875</td>\n",
              "      <td>1.064500</td>\n",
              "      <td>0.925552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.899500</td>\n",
              "      <td>0.925330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1925</td>\n",
              "      <td>1.021200</td>\n",
              "      <td>0.926590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.881500</td>\n",
              "      <td>0.924715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1975</td>\n",
              "      <td>1.054200</td>\n",
              "      <td>0.926567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.922266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2025</td>\n",
              "      <td>1.103700</td>\n",
              "      <td>0.921516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.902400</td>\n",
              "      <td>0.925196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2075</td>\n",
              "      <td>1.050900</td>\n",
              "      <td>0.925373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.783700</td>\n",
              "      <td>0.926533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>1.053800</td>\n",
              "      <td>0.923450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.863400</td>\n",
              "      <td>0.922566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2175</td>\n",
              "      <td>1.024200</td>\n",
              "      <td>0.921628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.851200</td>\n",
              "      <td>0.923611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2225</td>\n",
              "      <td>1.045400</td>\n",
              "      <td>0.922864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.821900</td>\n",
              "      <td>0.920332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>1.084200</td>\n",
              "      <td>0.920001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.824500</td>\n",
              "      <td>0.920369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2325</td>\n",
              "      <td>1.047200</td>\n",
              "      <td>0.919638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.815300</td>\n",
              "      <td>0.918445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2375</td>\n",
              "      <td>1.008200</td>\n",
              "      <td>0.911893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.862100</td>\n",
              "      <td>0.916708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2425</td>\n",
              "      <td>1.054500</td>\n",
              "      <td>0.914169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.724600</td>\n",
              "      <td>0.913119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2475</td>\n",
              "      <td>0.998800</td>\n",
              "      <td>0.913480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.859600</td>\n",
              "      <td>0.913447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2525</td>\n",
              "      <td>1.078000</td>\n",
              "      <td>0.915547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.857100</td>\n",
              "      <td>0.917675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2575</td>\n",
              "      <td>0.998600</td>\n",
              "      <td>0.911094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.823600</td>\n",
              "      <td>0.911937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2625</td>\n",
              "      <td>1.011700</td>\n",
              "      <td>0.913931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.855800</td>\n",
              "      <td>0.914178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2675</td>\n",
              "      <td>0.987000</td>\n",
              "      <td>0.912314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.788400</td>\n",
              "      <td>0.911322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2725</td>\n",
              "      <td>0.984200</td>\n",
              "      <td>0.912044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.787100</td>\n",
              "      <td>0.911461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2775</td>\n",
              "      <td>1.053600</td>\n",
              "      <td>0.912414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.857600</td>\n",
              "      <td>0.912962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2825</td>\n",
              "      <td>1.034800</td>\n",
              "      <td>0.910388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.838800</td>\n",
              "      <td>0.911560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2875</td>\n",
              "      <td>1.009400</td>\n",
              "      <td>0.910315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.802500</td>\n",
              "      <td>0.909278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2925</td>\n",
              "      <td>1.004100</td>\n",
              "      <td>0.908662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.833100</td>\n",
              "      <td>0.908734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2975</td>\n",
              "      <td>0.971300</td>\n",
              "      <td>0.907240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.819600</td>\n",
              "      <td>0.908713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3025</td>\n",
              "      <td>1.134300</td>\n",
              "      <td>0.908993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.910720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3075</td>\n",
              "      <td>1.058700</td>\n",
              "      <td>0.908514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.813800</td>\n",
              "      <td>0.907755</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/utils.py:145: UserWarning: Could not find response key `[128006, 78191, 128007]` in the following instance: <|begin_of_text|>\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic. \n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: depression\n",
            "Conversation: #Person1#: Hey, how are you doing?\n",
            "#Person2#: Uh, I guess okay... kind of.\n",
            "#Person1#: Yeah, Mom said Daniel isn't doing so well. What's going on?\n",
            "#Person2#: Well, uh, for some reason I always thought raising kids would be a lot easier than it is.\n",
            "#Person1#: Yeah, I know. Tell me about it. What's, what's the problem?\n",
            "#Person2#: Well, for about six months, he's been really down, and sometimes, I can't get him out of bed in the morning to go to school. He just seems so depressed. I just can't figure it out.\n",
            "#Person1#: So, this has been going on like half a year?\n",
            "#Person2#: Yeah, kind of on and off, but I don't know. I... I just thought it would just kind of go away, and I just thought things would just get, I don't know, get better.\n",
            "#Person1#: Yeah, that's not, that's pretty worrrisome. Um, I mean, I've noticed he's not hanging out with Jared very much anymore. You know, is he... what's he doing when he's up?\n",
            "#Person2#: Well, uh, a lot of the time he's not up. He just kind of uh, stays in bed. [ Really? ] I just can't figure it out. I don't know.\n",
            "#Person1#: Yeah, that's, that's a big problem. I can see why you're really worried about him. Have you considered taken him to see a therapist, or a psychologist, or anybody?\n",
            "#Person2#: Ah, no. I, I... It's probably just a phase or something. I think some kids were picking on him at school, but I think that's stopped. He doesn't talk about it anymore, so I guess that's over.\n",
            "#Person1#: So, you're saying that he was like being bullied and stuff?\n",
            "#Person2#: Yes, yeah. But he didn't talk about it a lot. I thought it was just, you know, having some problems, and it just kind of would go away.\n",
            "#Person1#: Well, you know, I don't know about that with the bullying or whatever, but you know, this has been going on for a long time. You really need to seriously address it.\n",
            "#Person2#: I don't know. Uh, and well, his girlfriend just broke up with him, so I guess maybe that's had an impact on him.\n",
            "#Person1#: Yeah, it has. Uh, that explains a lot. Um, have you looked at his Facebook page lately? [ What? ] He posted some stuff, well, he was posting some stuff, I think it was last night around midnight, um, yeah, talking about how much life sucks, wishing he could just disappear. [ Oh! ] Um, you know, I can't remember exactly the words he said, but I know that it really, really worried me. Some of the things he wrote are signs of, they might be thinking about suicide.\n",
            "#Person2#: Ah, I, I, I just can't figure that out. I mean, kids sometimes just talk like that. I, I, I thought. I thought that was kind of natural.\n",
            "#Person1#: Yes, sometimes they do that. That's what makes it hard. Sometimes, kids just talk like that, but some of them are serious, and some of them end up talking their own lives. Some of them really do kill themselves. You know, you need to take this seriously. Six months (of being depressed) isn't normal. Six months isn't just to act like this isn't just a phase. It's, there's something going on.\n",
            "#Person2#: So, any ideas? I mean, what should I do? I'm just kind of at a loss here.\n",
            "#Person1#: Oh, you know. I was talking to a woman the other day about her daughter. Um, there are crisis numbers you can call. Also, you could go to the hospital; you can do to the emergency room, and they do assessments there. Psychological assessments. [ Okay. ] Um, you know, it might be kind of hard to get him out to the hospital, to get him out to go with you if you can't get him out to go to school, but you need to take this seriously. [ Yeah... ] You could take him down to the hospital, down to the emergency room, so...\n",
            "#Person2#: I don't know.\n",
            "#Person1#: You know, it's really important. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_length`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/utils.py:145: UserWarning: Could not find response key `[128006, 78191, 128007]` in the following instance: <|begin_of_text|>\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic. \n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: job interview\n",
            "Conversation: #Person1#: Hi. Thanks for coming to the interview today. It's nice to meet you.\n",
            "#Person2#: Well, thank you.\n",
            "#Person1#: To begin with, why don't you tell us a little about yourself?\n",
            "#Person2#: Okay. Um, yeah. I've always been interested in teaching in a language program like this, and uh, I graduated with a degree in English and psychology eight years ago, [ Oh, really, both? ]. Yeah, and uh then I landed my first job overseas in Japan.\n",
            "#Person1#: Oh, wow. That's pretty impressive. What did you do there? What kind of work?\n",
            "#Person2#: Well, I worked full time, um, for a private language school in Tokyo for the first two years, and then I found a job at a community college.\n",
            "#Person1#: Oh really? So, exactly what did you do in your work there then?\n",
            "#Person2#: Well, I taught English and, uh, culinary arts.\n",
            "#Person1#: You taught cooking classes?\n",
            "#Person2#: Well, well, I know it sounds like an unusual combination, but I completed a program in culinary arts before I got my, uh, English and psychology degrees.\n",
            "#Person1#: Oh, Wow. You've done a lot, haven't you? [ Yeah. ] So, what exactly, um, how did you teach and what exactly did you do?\n",
            "#Person2#: Well, um, many of my students wanted to become chefs in restaurants, or they wanted to start their own restaurants, uh, and in our area, there were many, uh, tourists tourist spots. A lot of tourists came to that particular area, and so with English, they would be able to communicate not only with suppliers, you know things that they need for restaurant's food and so forth, but also with their customers, and so I taught them English and cooking at the same time.\n",
            "#Person1#: Wow. That's, that's pretty impressive. That's interesting. [... and tasty. ] Oh, I bet. So, why did you return to the United States? How long have you been back?\n",
            "#Person2#: I've been back for, uh, probably about a year now.\n",
            "#Person1#: Okay, so what brought you back then?\n",
            "#Person2#: Well, one of my former students opened a sushi restaurant, uh, in town, and he asked me to work with him.\n",
            "#Person1#: Really? What's the name of the restaurant?\n",
            "#Person2#: Well, it's called Flying Sushi. Have you ever heard of it?\n",
            "#Person1#: Yes, I've been there. Their food is fabulous; it's top-notch. It's really hard just to get a reservation there.\n",
            "#Person2#: I know, and uh, well, I work there two weeknights, and uh, and then...\n",
            "#Person1#: So, two nights a week you're working there still?\n",
            "#Person2#: Right, right, but then, but... I want to return to teaching. I've also been working as a therapist at a treatment center for teenagers struggling with depression and other mental health disorders.\n",
            "#Person1#: Oh, wow, that would be a really interesting job.\n",
            "#Person2#: It is, it is.\n",
            "#Person1#: Wow. You have such a wide range of experience. Uh, you know, to be honest, we have fifteen people who are applying for this position. You've got quite a background, but why don't you tell me three reasons why you would be the best person for this job.\n",
            "#Person2#: Um, well, first of all, uh, I understand that different students have different learning styles, and for that reason, I have used iPads, video, music, cooking, drama, role plays, and games to reach every student. [ That's good. ] And second, I have a background in academic and psychological counseling and advising [ Uh, huh ]... skills that are often needed, you know, in working with international students.\n",
            "#Person1#: Yeah, that could be really useful.\n",
            "#Person2#: Yeah, so you know, many of them struggle with, uh, emotional turmoil, you know, home sickness....\n",
            "#Person1#: Yeah, coming to a new place...\n",
            "#Person2#: Right, so making the transition can be very overwhelming, and uh...\n",
            "#Person1#: Good. So, what would you say would be a third reason?\n",
            "#Person2#: And finally, I speak four different languages....\n",
            "#Person1#: Four? Wow! What languages do you speak?\n",
            "#Person2#: Well, I speak Spanish, Portuguese,. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_length`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/utils.py:145: UserWarning: Could not find response key `[128006, 78191, 128007]` in the following instance: <|begin_of_text|>\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic. \n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: bearded dragons\n",
            "Conversation: #Person1#: Hi and welcome to our new show, Exotic Animal Kingdom, a program geared toward introducing animals to the young and old. In today's show, our young, but experienced, guest will introduce us to the fantastic world of bearded dragons. Welcome, Joshua. [Thank you very much.] Now, Joshua, I must admit that a bearded dragon sounds something like out of a fantasy book. What exactly is a bearded dragon?\n",
            "#Person2#: Well, here. Why don't you hold on to Bert, [Oh... Wow!] while I talk about him. [Okay] Bearded dragons actually originated from the deserts of Australia, and this is one of several species that survived in that climate. Today, beardies like this one are bred in captivity here in the US.\n",
            "#Person3#: Okay. And, so what are some of the essential things to know when getting a bearded dragon? I mean, can you raise one as a family pet?\n",
            "#Person2#: Bearded dragons make a great family pet and are very docile creatures.\n",
            "#Person1#: Yeah, this one seems quite friendly.\n",
            "#Person2#: You just need to know how to care for them.\n",
            "#Person1#: Well, what are some of the things you should keep in mind?\n",
            "#Person2#: First, you need to have the right supplies: some kind of enclosure...\n",
            "#Person1#: Like, like a cage or something like that.\n",
            "#Person2#: Yeah. [Okay] A full spectrum fluorescent light bulb and a basking lamp [Okay], branches and rocks to climb on and bask on, a food or water dish, and something to line bottom of the cage.\n",
            "#Person1#: Okay, well, let's get down to some the basics. What are the dietary needs of a bearded dragon? It sounds like a very carnivorous beast. Perhaps, uh, they eat fiery Mexican tacos or something like that.\n",
            "#Person4#: No, bearded dragons are omnivores...\n",
            "#Person1#: Now, Omnivores? What exactly is that?\n",
            "#Person2#: Uh, creatures that eat insects, vegetable, and greens, the leafy parts of plants and their stems.\n",
            "#Person1#: Okay. You mean like, for example, carrots or something like that for example. [Yeah] Okay.\n",
            "#Person2#: Young dragons like Bert can be fed small crickets twice a day, along with some greens and shredded vegetables. [Okay.] And then as your dragon grows, you can increase the amount of greens and vegetables. [Alright.] And you can also dust the vegetables and insects with a calcium supplement to promote bone growth.\n",
            "#Person1#: Okay, and what about water? Uh, what kind of needs do they have for that?\n",
            "#Person2#: Well, since bearded dragons traditionally live in arid regions, they obtain most of their water naturally from what they eat, so you have to be sure to feed them plenty of vegetables that serve as good carriers of water. [Okay.] You also spray them occasionally with a water bottle or provide them with a shallow water dish. Whatever you do, but sure to keep the cage dry, [Okay.] or else mold and bacteria can grow that could make your dragon sick. [Okay.], and finally, you mentioned about lighting earlier. What do you need exactly to keep your beardie happy and healthy?\n",
            "#Person5#: Having a full spectrum light and basking lamp are pretty key to raising healthy beardies. First, they need the simulated sunlight from the ultraviolet UV bulb...\n",
            "#Person1#: Now, is that the full spectrum light that you mentioned? Okay.\n",
            "#Person2#:... to absorb rays [Okay.], vital to the production of certain vitamins, [Okay.] and the high body temperatures of a basking light to aid in the digestive process.\n",
            "#Person1#: Now, what kinds of temperatures are you referring to when you talk about the basking area?\n",
            "#Person2#: Like ninety to a hundred degrees.\n",
            "#Person1#: Okay, and I don't think they need sun tan lotion, right? [No]. Okay, uh, so, perhaps then, I could put my beardie in an aquarium and just set him by the window which gets direct sunlight? Would that work?\n",
            "#Person2#: Well, actually, you can even take them outside two or three times a week in the direct sunlight; however, putting them in a glass aquarium with exposure to sunlight won't be viewed as a replacement for direct light or a UV bulb because the glass only filters out the sunlight they need.\n",
            "#Person1#: Wow! I didn't know there was so much to know about raising a pet like that. Well,. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_length`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/utils.py:145: UserWarning: Could not find response key `[128006, 78191, 128007]` in the following instance: <|begin_of_text|>\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic. \n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: rent an apartment\n",
            "Conversation: #Person1#: Hello.\n",
            "#Person2#: Hi. I'm calling about the ad for the apartment found in today's newspaper.\n",
            "#Person1#: Okay.\n",
            "#Person2#: I'm kind of desperate, and I need something right away.\n",
            "#Person1#: Okay. What would you like to know?\n",
            "#Person2#: First of all, how big is it?\n",
            "#Person1#: It's a two-bedroom apartment with a living room, dining room and kitchen, and one bathroom. There's also a place for a washer and dryer.\n",
            "#Person2#: Okay, and how old is the apartment complex?\n",
            "#Person1#: Well, let's just say it has a lot of history. To be honest, my great grandfather built it during the 1920s, but it's a very sturdy and sound structure.\n",
            "#Person2#: Oh, and... so, is the apartment furnished at all?\n",
            "#Person1#: Oh, yeah. The apartment is partially furnished with a refrigerator, stove, and my grandmother's old dishwasher.\n",
            "#Person2#: Your grandmother's old dishwasher? Okay. What's the rent?\n",
            "#Person1#: It's $950 a month.\n",
            "#Person2#: Whoa. That is a little steep for me.\n",
            "#Person1#: But you could always split the cost with a roommate.\n",
            "#Person2#: Perhaps. Does that include utilities?\n",
            "#Person1#: Well, the rent includes gas and electricity, but not the phone bill. And the water pump is right out the back door.\n",
            "#Person2#: Water pump!\n",
            "#Person1#: Yeah.\n",
            "#Person2#: Oh, yeah. Well, can I rent month-to-month, or do I have to sign a lease for a longer period of time?\n",
            "#Person1#: We require a 6-month commitment for the apartment, and if you cancel the agreement anytime during that period, hey... you lose your deposit.\n",
            "#Person2#: Oh, and how much is the deposit?\n",
            "#Person1#: It's $400, and, of course, this money is used to repair damage or general wear and tear on our apartment, like the leaks in the old roof from last year's snow storm. Man, that was ugly. Plaster falling down from the ceiling. And I didn't even know there was a rat's nest up there, but we got that taken care of.\n",
            "#Person2#: A what? Do I get my deposit back after I move out? That's assuming that I even move in.\n",
            "#Person1#: Generally speaking, we return the deposit, minus a small fee for, you know, cleaning the apartment for the next tenant, but if you trash the place, then don't expect to get anything back.\n",
            "#Person2#: Okay. Oh, um... how close is the apartment to the university campus?\n",
            "#Person1#: It's about eight blocks from campus, but you can catch a number of busses right out in front.\n",
            "#Person2#: Oh, so, then, if there's a busy road out front, is it noisy?\n",
            "#Person1#: Well, there are always trade-offs: it's a little noisy with the road outside and the airport behind you, but the place is really convenient because there's a supermarket and shopping center right across the street. Just keep the windows closed and a pair of ear plugs handy, and you'll be fine.\n",
            "#Person2#: Okay, and one last question. Are there parking spaces for tenants?\n",
            "#Person1#: Yeah. The apartment has two covered parking spaces, which are really convenient during certain times of the year.\n",
            "#Person2#: Uh... I don't know. Is it possible for me to drop by and visit the apartment tomorrow morning?\n",
            "#Person1#: Sure, but just remember we rent the apartment on a first-come, first-serve basis, so there's no guarantee it'll still be available then.\n",
            "#Person2#: Okay. Thanks. Um... and where exactly is the apartment located?\n",
            "#Person1#: It's one block west of the waste water treatment plant.\n",
            "#Person2#: Ah.... Are pets allowed?\n",
            "#Person1#: Well, you can keep small pets like a hamster in a small cage, but we don't allow larger animals like dogs, cats, or snakes. Things like that.\n",
            "#Person2#: Um, I have a rat...\n",
            "#Person1#: You don't have anything like that, do you?\n",
            "#Person2#: Well, I have a rat that I keep in a cage. Will that be okay?\n",
            "#Person1#: Well, as long it doesn't escape, I guess that's okay.\n",
            "#Person2#: And what's your name?\n",
            "#Person1#: It's Norman. Norman Bates.\n",
            "#Person. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_length`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/utils.py:145: UserWarning: Could not find response key `[128006, 78191, 128007]` in the following instance: <|begin_of_text|>\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic. \n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: drug addiction\n",
            "Conversation: #Person1#: Hey, Brandon.\n",
            "#Person2#: Yeah.\n",
            "#Person1#: Um... Um...\n",
            "#Person2#: What?\n",
            "#Person1#: Well, I need to talk to you, and I'm not really sure how to do it. It's kind of difficult, but I kind of, I need to talk to you about something.\n",
            "#Person2#: Alright. Go ahead.\n",
            "#Person1#: Okay. You know, Stephanie. [Yeah.] You're dating my sister, right? Stephanie. [Yeah, yeah.] Um, I think she's back on drugs.\n",
            "#Person2#: What do you mean? I, I know she had a problem in the past, but she told me that that was over.\n",
            "#Person1#: Well, that's what she says, but you know, I know my sister pretty well; I think I know her better than just about anyone else, and I know you guys have talked about getting married soon, and [Yeah]... I'm pretty sure she's using drugs again, and you really need to, you need to know this... you really need to face the facts, and you're going to have to deal with this now.\n",
            "#Person2#: So, but, I... again, how do you know?\n",
            "#Person1#: She's doing some of the same stuff, you know, um, like. Well, like. Listen, you know. Um, you've noticed she's been skipping work lately?\n",
            "#Person2#: Well, she said she's been having some health problems, so I just figured it was that.\n",
            "#Person1#: No, no, no. She's not. [ Are you sure? ] Yeah. It's, it's more than that. Like, a month ago, she asked me to lend her a thousand bucks to fix her car.\n",
            "#Person2#: Wow. Man. Um, I mean, she didn't tell me anything like that. I mean, her car is running fine, I think.\n",
            "#Person1#: Yeah, I know, it is. It's running fine. [ Oh, great. ] Exactly. She's lying a lot now, and she's, you know, she's trying to hide it, and she's good at hiding it.\n",
            "#Person2#: And, I let her borrow my car a couple days ago, and I had fifty bucks in there, and when the car came back, it was gone. She's... I don't know how else it could have disappeared. [ Man. I can't belive this. ] I'm pretty sure she stole it.\n",
            "#Person1#: I know. Um, but she's hiding things, and she hides things from us, and okay, for example, like last week. I saw her with the two cell phones, and when I checked the texts on the one phone....\n",
            "#Person2#: Wait, wait. Two phones? What do you mean?\n",
            "#Person1#:....Yeah, umm.\n",
            "#Person2#: She only has one.\n",
            "#Person1#: No, she's got at least two phones, and when I checked the one phone, I saw some texts, and she was talking about, um, um, some drugs and needing to meet up with someone to buy them.\n",
            "#Person2#: Ah, man.\n",
            "#Person1#: I'm sorry, Brandon, um, I... we need to, we need to confront her on this. You need to confront her on this.\n",
            "#Person2#: I don't know how to do this. I mean... yeah, I don't know.\n",
            "#Person1#: I know, but you've got to. You, you can't... the... you know, you've got to do this if you want to try to hope that there's going to be anything to this relationship. It's, it's much better to talk to her openly about this now, cause, I promise you, the problems will just escalate, so...\n",
            "#Person2#: But, she might blow up.\n",
            "#Person1#: She might, but hey, wait, listen. Why don't you guys come over for dinner and we can talk about it together? You know, um...\n",
            "#Person2#: I just don't know.\n",
            "#Person1#: I know, and you're right, she might blow up, but if you don't do anything, I promise the problems are just going to get bigger. She's probably going to end up losing her job, she's probably going to get arrested, and she might even die.\n",
            "#Person2#: Man, you're probably right. I have to think about this and how to approach her. Alright. Let, let me thing about it, and. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_length`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/utils.py:145: UserWarning: Could not find response key `[128006, 78191, 128007]` in the following instance: <|begin_of_text|>\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic. \n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: tiny televisions\n",
            "Conversation: #Person1#: Well, I'm sure all our listeners would love to be brought up to date on the latest in tiny televisions.\n",
            "#Person2#: It's an expanding market, that's for sure, and they seem to be getting smaller every year.\n",
            "#Person1#: Which countries are dominating the market?\n",
            "#Person2#: At the moment it's Japan, principally. In the spring of 1982 Sony introduced the Watchman?\n",
            "#Person1#: Is that the Walkman?\n",
            "#Person2#: No, the Watchman is a portable black and white TV set with a tiny screen and aerial.\n",
            "#Person1#: How big is the whole thing?\n",
            "#Person2#: Oh, I'd say about 35 cm by 12 cm and it weighs only a couple of kilograms.\n",
            "#Person1#: Was it a success from the start?\n",
            "#Person2#: Funnily enough, a Sony executive said that no one would want to watch a TV while walking around-and also a slightly larger model could be bought for half the price!\n",
            "#Person1#: Really?\n",
            "#Person2#: But, despite this pessimistic view, sales of this model far outnumbered projections.\n",
            "#Person1#: Well, you never can tell! How big was the initial production?\n",
            "#Person2#: The company started with 2,000 units per month and increased to 5,000 by the end of 1982, but they still couldn't keep up with the demand.\n",
            "#Person1#: So I suppose they upped the production levels even higher.\n",
            "#Person2#: It was much more radical than that! In the spring of 1983 Sony pulled out all the stops and launched the Watchman all over again with a new model.\n",
            "#Person1#: Oh, what's it like?\n",
            "#Person2#: Well, it's 20 per cent smaller and the price is 25 percent less...\n",
            "#Person1#: Mmmm.\n",
            "#Person2#: and the components were designed from scratch.\n",
            "#Person1#: And what about production levels?\n",
            "#Person2#: They quadrupled to 20,000 units a month just for the Japanese market!\n",
            "#Person1#: Wow! The Watchman certainly seems to have taken off.\n",
            "#Person2#: Indeed it has.\n",
            "#Person1#: And I believe there were other Japanese companies as well.\n",
            "#Person2#: Yes. At the end of 1982 Hattori-that's H-A-T-T-O-R-I--you know, the makers of Seiko watches-well, they unveiled an even smaller TV, around 3era, which is built into a wrist-watch.\n",
            "#Person1#: Incredible!\n",
            "#Person2#: It certainly is. The rest of the set is carried separately in your pocket and it's about the size of a packet of kingsize cigarettes.\n",
            "#Person1#: And how does it work?\n",
            "#Person2#: It has a liquid crystal display screen. The TV receiver and battery pack fit into your pocket, and they're connected by a cord to the watch.\n",
            "#Person1#: Is there a headphone?\n",
            "#Person2#: Oh, yes, that's plugged into the receiver as well.\n",
            "#Person1#: Seems a bit complicated, that one, with all the wires and bits and pieces.\n",
            "#Person2#: Yes, it does.\n",
            "#Person1#: Any other Japanese models?\n",
            "#Person2#: Yes, Casio-that's C-A-S-I-O. Their latest is a calculator-sized TV about one-third the bulk of the Watchman and with 1983 production figures of 2000 units a month.\n",
            "#Person1#: I see.\n",
            "#Person2#: And, according to a spokesman, they hope to match their calculator sales, which are about 25 million units per year.\n",
            "#Person1#: Very impressive. And no doubt other Japanese companies will jump on the bandwagon.\n",
            "#Person2#: Most likely.\n",
            "#Person1#: Now, could you tell us about other countries making these tiny TVs?\n",
            "#Person2#: Of course. From Sinclair in England there's one similar in size to the Casio, and their production levels were 1 million for 1983.\n",
            "#Person1#: Obviously they're planning on backing a winner!\n",
            "#Person2#: How right you are. A representative said they expect a mass-market response, not just a novelty item.\n",
            "#Person1#: And just which market are the manufactures aiming at?\n",
            "#Person2#: Mainly the commuters who spend hours going to and from work. These TVs will provide relief from the monotonous train and bus rides.\n",
            "#Person1#: Well, thank you for keeping us in touch with this extremely popular gadget.\n",
            "#Person2#: My pleasure, and happy viewing to all of you with those TVs.\n",
            "\n",
            "<|eot_id|>. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_length`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/utils.py:145: UserWarning: Could not find response key `[128006, 78191, 128007]` in the following instance: <|begin_of_text|>\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic. \n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: interview\n",
            "Conversation: #Person1#: Let's begin by having you tell me about yourself and your background. \n",
            "#Person2#: I have been working as a paralegal for the last 10 months through an agency that specializes in the legal field. My experience has been supporting attorneys in the field of labor law, where I have been able to apply my paralegal education. I was commended on my ability to take information and break it down into usable facts. I really love research and analyzing facts. My major in college was English, and as a result, my writing skills are my major strength. I am looking for a position where my research and writing skills can be used. \n",
            "#Person1#: What do you think are the key qualities needed to succeed in the paralegal profession? \n",
            "#Person2#: Flexibility would certainly rank high in this type of job. In my last position, I supported four lawyers, and it was not unusual for them all to give me high-priority items to do in the same day or week. There were days when I had to stop and prioritize my work just to get a handle on everything. I would discuss the urgency of their work with each of them so I didn't drop the ball. At the same time, I made sure each of them felt like his or her project was important on my agenda. I think communication is probably the next key quality. It really worked well when I talked with each of them, explained my situation, and got their input. \n",
            "#Person1#: Can you give me an example of a time when you had to work above and beyond your job description? \n",
            "#Person2#: There was a very important project that had to be researched and completed by the end of the week. Even though I worked extra hours every night for almost two weeks, my boss and I stayed until 2 a. m. for two nights before the final wrap up. It was very rewarding to have put so much effort into a project and see the really great results. My boss gave me a bonus for my extra effort. \n",
            "#Person1#: Tell me about a time when you had to research a case and encountered some obstacles you had to overcome. \n",
            "#Person2#: I remember a case that was filled with obstacles. The first thing I did was research through documents and past cases that had similar circumstances. I assembled the facts and then tried to put them together and analyze the next step. I was able to get some input from another lawyer I happened to see at lunch. Through some hard work and fact digging, I was able to find a way to overcome most of the obstacles. I took my findings to my boss and made some recommendations, which she and I discussed and eventually resolved. My boss was impressed with the work I had done. \n",
            "#Person1#: What are your strengths and weaknesses? \n",
            "#Person2#: My strengths are my caring about getting the job done. I am very results-driven and have been able to meet all my deadlines in past jobs. As far as weaknesses, I really enjoy my work, and sometimes I put in too much time. But I am aware of my tendency to overwork and have learned to pace myself more. \n",
            "#Person1#: Tell me about a time when you had a confrontation with a coworker or boss. \n",
            "#Person2#: I did have an issue with someone who was getting on my nerves. I asked her if I could talk with her one day, and we had a good discussion. It turned out she was not aware of the impact of her actions and that she really needed an explanation of the procedure. I took the time to explain the procedures, and there haven't been any problems since that day. \n",
            "#Person1#: When do you find a job satisfying? \n",
            "#Person2#: My biggest satisfaction is when I experience growth in a job. When I first started as a paralegal, I had a lot to learn. But through hard work, advice from some good mentors and continuing education, I have come a long way. I've learned to be flexible when possible and to deal with difficult people in a positive manner. \n",
            "#Person1#: How would your coworkers describe you? \n",
            "#Person2#: First, they'll say I have a lot of energy and enthusiasm. I really enjoy working with people. Secondly, they'll say I had great customer service skills. I put the customer first. And thirdly, they'll say that I know the law. I put a lot of effort into my education as a paralegal and take it seriously. \n",
            "#Person1#: Do you have any questions? \n",
            "#Person2#: Yes, I do. On a scale of one to 10, what would you say morale was in this company. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_length`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/utils.py:145: UserWarning: Could not find response key `[128006, 78191, 128007]` in the following instance: <|begin_of_text|>\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic. \n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: new neighbor\n",
            "Conversation: #Person1#: Hi.\n",
            "#Person2#: Oh, Hi.\n",
            "#Person1#: Are you new in the neighborhood?\n",
            "#Person2#: Oh, yeah.\n",
            "#Person1#: Welcome, welcome to the neighborhood.\n",
            "#Person2#: Oh.\n",
            "#Person1#: Hey, I'm Stacy. I live across the street.\n",
            "#Person2#: Oh, Hi, Stacy. I'm Mark. Mark Jones.\n",
            "#Person1#: Um. Looks like your moving. Do you need any help unloading your moving truck? I can have my husband come or my kids.\n",
            "#Person2#: Um, well, fortunately, the movers are going to do that, but you're welcome to, uh, help carry in a few things out from our car.\n",
            "#Person1#: Yeah, sure, I can get them. So, where are you from?\n",
            "#Person2#: Well, we're from originally from Chicago, but we just moved from a place called Springville.\n",
            "#Person1#: Oh, Springville, that's, uh. Isn't that the... the north end of the state\n",
            "#Person2#: Yeah, just, yeah, not too far from here.\n",
            "#Person1#: How was your trip?\n",
            "#Person2#: Well, it went pretty well. We hired a moving company, something my company paid for, and it was simply more convenient than packing all our stuff, renting a truck, and then moving everything ourselves.\n",
            "#Person1#: That's nice. How does this moving company work then? Was it pretty good?\n",
            "#Person2#: Yeah. Well, in many cases, you can pack your own things and just have the company load the boxes and your other items on the truck, or they'll pack everything for you, and they can tow your vehicle behind the truck if you like, and they can even, you know, move heavy items like pianos.\n",
            "#Person1#: Wow, that's nice. So, did everything go as planned?\n",
            "#Person2#: Well, pretty much, except our cat disappeared\n",
            "#Person1#: Really?\n",
            "#Person2#: Yeah, about three hours before the movers left...\n",
            "#Person1#: Did you ever find it?\n",
            "#Person2#: No, and uh, we're not sure if she ran away, got hit by a car, or what.\n",
            "#Person1#: Oh, that must be really hard on your family. Sorry to hear about that.\n",
            "#Person2#: Yeah.\n",
            "#Person1#: Yeah, that must be rough.\n",
            "#Person2#: Yeah.\n",
            "#Person1#: No sign of the cat?\n",
            "#Person2#: Not yet.\n",
            "#Person1#: Uh, I'm sorry. So, um, what do you do for a living?\n",
            "#Person2#: Well, I'm software developer.\n",
            "#Person1#: Oh, what do you do exactly in your job?\n",
            "#Person2#: Well, um, most of the time, I develop educational software for schools.\n",
            "#Person1#: Really?\n",
            "#Person2#:... Yeah, and at the moment, I'm working on several educational apps for, you know, smart phones.\n",
            "#Person1#: Oh, that's... that's great.\n",
            "#Person2#: Yeah, it's a really good job. And, so, how about yourself?\n",
            "#Person1#: Well, actually, I'm a high school history teacher.\n",
            "#Person2#: Oh, wow, you know, actually, I've created two apps on world history that you might be interested in.\n",
            "#Person1#: Serious?\n",
            "#Person2#: Yeah.\n",
            "#Person1#: Oh, that sounds great. I'd love to see them.\n",
            "#Person2#: Yeah.\n",
            "#Person1#: By the way, um, you know, we're having a barbecue at our place on Friday.\n",
            "#Person2#: Oh?\n",
            "#Person1#: Why don't you come over... bring your family and get to know some of the neighbors?\n",
            "#Person2#: Well, let me talk to my wife, but just so you know, we have nine kids.\n",
            "#Person1#: Serious? Nine kids? Wow!\n",
            "#Person2#: Yes, so they might eat all your food.\n",
            "#Person1#: Well, that's no problem. That's a lot of kids, but it'll be fun. Hey...\n",
            "#Person2#: What?\n",
            "#Person1#: No, just listen.\n",
            "#Person2#: Hey.\n",
            "#Person1#: Did you hear that? Listen, listen. It's coming from over there. It's in one of the... there something in one of your boxes.\n",
            "#Person2#: No way. Yeah.\n",
            "#Person1#: That sounds... That sounds like a cat. Is the cat in one of your... Did you find... Did the. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_length`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/utils.py:145: UserWarning: Could not find response key `[128006, 78191, 128007]` in the following instance: <|begin_of_text|>\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic. \n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: a 72-hour kit\n",
            "Conversation: #Person1#: Hi, Tim. So, are you doing some last-minute shopping before the weekend?\n",
            "#Person2#: Well, actually, I'm looking for supplies to put together 72-hour kits for each member of my family.\n",
            "#Person1#: [A] 72-hour kit? What's that?\n",
            "#Person2#: Basically, a 72-hour kit contains emergency supplies you would need to sustain yourself for three days in case of an emergency, like an earthquake.\n",
            "#Person1#: An earthquake?! We haven't had an earthquake in years.\n",
            "#Person2#: Well, you never know; you have to be prepared. Hey, if earthquakes don't get you, it could be a flood, hurricane, snowstorm, power outage, fire, alien attack. [Alien attack!] Well, you never know. Think of any situation in which you might find yourself without the basic necessities of life, including shelter, food, and water, for over a period of time.\n",
            "#Person1#: Hum. So, what do you keep in a 42-hour, um,... I mean 72-kit?\n",
            "#Person2#: Well, you should have enough food and water to last you three days, and you might want to pack a basic water filter or water purification tablets in case your only water source turns out to be a murky pool of bug-infested water. [Ugh!] Hey, sometimes you don't have a choice, and as for food, you should keep it simple: food that requires no preparation and that doesn't spoil. And no canned goods because they are often too heavy and bulky. [Okay, that makes sense.] And unless you have a can opener or the can has a pull-tab lid, you'll have to use a rock or something to open them. [Ah, instant mashed green beens.] Yeah, and oh, energy bars, beef jerky, and a mix of nuts, raisins, and chocolate are possibilities.\n",
            "#Person1#: Huh, the food might be nasty, but I guess you could survive... barely.\n",
            "#Person2#: Well, the food doesn't have to taste bad; just select things that are easy to prepare, and you might want to include some basic comfort foods like a couple of candy bars. Then, you have to decide on the type of shelter you might need.\n",
            "#Person1#: A hotel sounds nice.\n",
            "#Person2#: Yeah, but that's really not an option. The reality is that you might have to evacuate to a shelter, possibly with hundreds or thousands of other people.\n",
            "#Person1#: That doesn't sound very fun... everyone packed together like sardines in a can. Unsanitary conditions. Disease.\n",
            "#Person2#: Ah, now you're sounding paranoid, but if a shelter isn't available, you might be completely on your own, so I always pack an emergency sleeping bag or small, lightweight tent in the event that I have to survive on the street or in a park.\n",
            "#Person1#: Wow.\n",
            "#Person2#: And among other things, you should pack a flashlight, portable radio, extra batteries, a small first-aid kit, personal items like a toothbrush or toothpaste... Having a change of clothing is also important.\n",
            "#Person1#: What about money? I have a credit card.\n",
            "#Person2#: Right. Like that's going to help when the power is out. You'd better be prepared with coins and cash, and having small bills is a must.\n",
            "#Person1#: So, what do you do to communicate with other family members in case you get separated?\n",
            "#Person2#: Oh, in that case? I always pack two-way radios to communicate with the group. You can never depend on cell phones. [Okay.] Plus, you should decide on a meeting point in case your family gets separated.\n",
            "#Person1#: Well, that sounds like a detailed plan, definitely.\n",
            "#Person2#: Oh, that's not all. You never know what weather conditions you might encounter, so packing a rain poncho, a jacket, and something to start a fire with could be very useful.\n",
            "#Person1#: Like Matches?\n",
            "#Person2#: Matches? If You drop those in a puddle of water, you're toast. You need to pack at least three forms of fire starter: a magnifying glass, a high-quality lighter, and waterproof matches.\n",
            "#Person1#: Wow. I never thought about those either. So, what do you do if you have small kids? They'd probably go stir-crazy under such conditions.\n",
            "#Person2#: You're exactly right, so a little extra preparation for them is needed. If you have to evacuate to a shelter to wait out a disaster, kids. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_length`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/utils.py:145: UserWarning: Could not find response key `[128006, 78191, 128007]` in the following instance: <|begin_of_text|>\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "You are an expert on summarizing conversations considering a particular topic. \n",
            "The user request will contain the topic and the conversation\n",
            "Answer with the summary only. Do not explain your answer\n",
            "<|eot_id|>\n",
            "\n",
            "<|start_header_id|>user<|end_header_id|>\n",
            "Topic: rent a car\n",
            "Conversation: #Person1#: Hi. How can I help you?\n",
            "#Person2#: Yeah. I'd like to rent a mid-size car for three days.\n",
            "#Person1#: Okay. Let me check to see if we have one available. Hmmm. It's doesn't look like we do. We have a couple of economy, compact, and full-size cars available, or a nice minivan.\n",
            "#Person2#: Well, what is the main difference between these cars?\n",
            "#Person3#: The main difference is size. The economy car is the smallest, and it seats fewer passengers and can hold less luggage. [Okay.] How many people are with you?\n",
            "#Person2#: Just me and my son.\n",
            "#Person1#: Well, the economy car would work. We have one right out front.\n",
            "#Person2#: Where? That one? It looks more like a shoebox to me. I'm really tall and trying squeeze into that thing... I don't think so.\n",
            "#Person1#: Well, if you need more room or comfort, I recommend the full-size car. It also has a nice stereo system, CD player, [Alright] safety rear door locks, and cruise control, and power locks and windows.\n",
            "#Person2#: Well, I'm not so concerned about how it's equipped. I just want to make sure it is comfortable to drive. And what is the daily rate for that anyway?\n",
            "#Person1#: Well, let's see here. Oh, yeah. It'll come to fifty-seven ninety-five a day.\n",
            "#Person2#: Wow, a little expensive. But what's the cost for mileage?\n",
            "#Person1#: Hey, all of our cars have unlimited miles, but of course, that doesn't include gas.\n",
            "#Person2#: Yeah, right. I bet that car probably eats up gas, and now that were in the middle of the vacation season, gas stations are gouging consumers with astronomical prices.\n",
            "#Person1#: Well, as they say, it comes down to the law of supply an demand.\n",
            "#Person2#: Well, anyway, can you install a car seat in one of those cars? I have a 3-year-old son with me.\n",
            "#Person1#: Sure, and that'll only be one dollar extra per day.\n",
            "#Person2#: I'll go with the full-size car. Wait, uh... what does it look like?\n",
            "#Person1#: Uh, it's right out there in the parking lot. [Which one?] The one over there next to the sidewalk.\n",
            "#Person2#: Do you mean that old lemon with the missing hubcap? Ahhh.\n",
            "#Person1#: Sir, excuse me. We take pride in our vehicles. It's just that it's one of the last cars on our lot, but it runs like a dream. Don't let the exterior fool you. Hey, I'll even give you an extra fifteen dollars off the daily rate to show you we are serious about pleasing our customers. Will there be any other drivers?\n",
            "#Person2#: No, I'm the only driver.\n",
            "#Person1#: Okay. Would you like to purchase our daily car protection plan?\n",
            "#Person2#: What's that exactly?\n",
            "#Person1#: Well, the car protection plan is a complete insurance package covering damage to the vehicle, [Okay] injury or loss of life to you or your passengers [Oh]. It even includes incidental road damage caused by, let's say, a huge boulder rolling down the mountain and crushing your car. [Oh, uh, well... ]. However, it won't cover loss of property due to theft. Too much crime in the area anyway. [What? Wh... What about this crime? What, what?]. Don't worry about it. And the car protection plan is only seventeen ninety-five per day. [But you were saying?] And the nicest thing about this coverage is that you can rent the car without the worry and hassle of making a complicated claim in case you do have a problem.\n",
            "#Person2#: But wouldn't my own car insurance cover those problems?\n",
            "#Person1#: It might, but each insurance policy is different. With our car protection plan, however, you deal directly with us in case there is a problem [Well... ], and we handle everything quickly, and you don't have to contact your own insurance company. Okay. Let me just confirm this. A full-size car with a car seat for three days [Yeah], plus the car protection package. Is that right? [That's right.] Okay, I'll have our mechanic, Louie, check the car over and pull it up to the door.\n",
            "#Person2#: Push it up to the door? I hope this car really runs.\n",
            "#. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_length`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "training_history = peft_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFYfeutY7RHD"
      },
      "source": [
        "## Save the adapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1ngM4qVkkSU"
      },
      "outputs": [],
      "source": [
        "peft_model.save_pretrained(f\"{output_dir}/best_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model adapter is saved inside the `best_model` folder"
      ],
      "metadata": {
        "id": "5tZuoQiPCy1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVQlTXl4kkSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4108fd4-be9c-4d6d-f839-b0cf0f11d68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 19M\n",
            "drwxr-xr-x 2 root root 4.0K Mar 28 09:19 .\n",
            "drwxr-xr-x 4 root root 4.0K Mar 28 09:19 ..\n",
            "-rw-r--r-- 1 root root  815 Mar 28 09:19 adapter_config.json\n",
            "-rw-r--r-- 1 root root  19M Mar 28 09:19 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root 5.0K Mar 28 09:19 README.md\n"
          ]
        }
      ],
      "source": [
        "!ls -lah \"{output_dir}/best_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now jump to the [evaluation notebook](https://drive.google.com/file/d/1q3rR9-JsKaeWi9kCL0OAlERt76dlsWW5/view?usp=sharing) to load and test the trained model"
      ],
      "metadata": {
        "id": "OtIveT6IDtKl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdMiYomiDXDg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49f395c0bd994ad393490b3e13e214a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ea44d3f0fd14c23961b41e423ce8b88",
              "IPY_MODEL_9957737a36e74e73bd55cbbc82bd5bf1",
              "IPY_MODEL_d4ee39c8e3734784b94bbe52f15693bf"
            ],
            "layout": "IPY_MODEL_48f2849f8b3c45d7b045b6f2e3ad61cf"
          }
        },
        "8ea44d3f0fd14c23961b41e423ce8b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1920ee83f5b4497b7924e85070ce844",
            "placeholder": "​",
            "style": "IPY_MODEL_f13e1c19bc6342efab3224aa968094aa",
            "value": "Map: 100%"
          }
        },
        "9957737a36e74e73bd55cbbc82bd5bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dfda9a9e87147c380a7d2b5123ad8de",
            "max": 12460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4005c16581a4e488083da2fd76c505f",
            "value": 12460
          }
        },
        "d4ee39c8e3734784b94bbe52f15693bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6901d4c7a20449419a2b85ea90a55adb",
            "placeholder": "​",
            "style": "IPY_MODEL_0c82273dab134d19b54e0c8c405b95cd",
            "value": " 12460/12460 [00:01&lt;00:00, 11346.07 examples/s]"
          }
        },
        "48f2849f8b3c45d7b045b6f2e3ad61cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1920ee83f5b4497b7924e85070ce844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13e1c19bc6342efab3224aa968094aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dfda9a9e87147c380a7d2b5123ad8de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4005c16581a4e488083da2fd76c505f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6901d4c7a20449419a2b85ea90a55adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c82273dab134d19b54e0c8c405b95cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5c24a221f0f4efc81b9b1d2636757c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f54216828bf146eb8a2172abe1f04948",
              "IPY_MODEL_c05cd5d009944de6a8780d03cfadb07f",
              "IPY_MODEL_b896b96c80814291bf68d6ff3d9ff868"
            ],
            "layout": "IPY_MODEL_a9cda1616eea43f0b74b8822b204a4ff"
          }
        },
        "f54216828bf146eb8a2172abe1f04948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea00e87172f44933905d55641db8ad5d",
            "placeholder": "​",
            "style": "IPY_MODEL_869f76dadb824935b398476dc1220f3f",
            "value": "Map: 100%"
          }
        },
        "c05cd5d009944de6a8780d03cfadb07f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06cfb77ea21e4383a5c824ee1ff188ff",
            "max": 12460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dbf2a448a2a4782b0f699eab1b3986c",
            "value": 12460
          }
        },
        "b896b96c80814291bf68d6ff3d9ff868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ddc027a6d6488784c948a14d7412fc",
            "placeholder": "​",
            "style": "IPY_MODEL_5e8745e5810441209035aa729bd44834",
            "value": " 12460/12460 [00:09&lt;00:00, 1406.51 examples/s]"
          }
        },
        "a9cda1616eea43f0b74b8822b204a4ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea00e87172f44933905d55641db8ad5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "869f76dadb824935b398476dc1220f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06cfb77ea21e4383a5c824ee1ff188ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dbf2a448a2a4782b0f699eab1b3986c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6ddc027a6d6488784c948a14d7412fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e8745e5810441209035aa729bd44834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4ad4041f3494c27beb7452ab53a6349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a17520f1b5eb4ed5a18d3684d28ed97c",
              "IPY_MODEL_86ac97c7f35a4788b0d7dddec4e388ce",
              "IPY_MODEL_d9b24cde5c48464f96e698c6b2f85d0f"
            ],
            "layout": "IPY_MODEL_257814a1cce04e81ab3e444e25f520b9"
          }
        },
        "a17520f1b5eb4ed5a18d3684d28ed97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f2c3e510fe4c6184157ea4806cbcfc",
            "placeholder": "​",
            "style": "IPY_MODEL_1645cc82fb1b4d7ebd1d8f00261130a3",
            "value": "Filter: 100%"
          }
        },
        "86ac97c7f35a4788b0d7dddec4e388ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9587b743e6f44f038495630313b95b45",
            "max": 12460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_781575583570456b8704d12b7ed0d3cb",
            "value": 12460
          }
        },
        "d9b24cde5c48464f96e698c6b2f85d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1a6003cce5a4771bea9d6e4345b6007",
            "placeholder": "​",
            "style": "IPY_MODEL_ee34f65022f640ee8388799ff495cf44",
            "value": " 12460/12460 [00:03&lt;00:00, 4011.36 examples/s]"
          }
        },
        "257814a1cce04e81ab3e444e25f520b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f2c3e510fe4c6184157ea4806cbcfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1645cc82fb1b4d7ebd1d8f00261130a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9587b743e6f44f038495630313b95b45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "781575583570456b8704d12b7ed0d3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1a6003cce5a4771bea9d6e4345b6007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee34f65022f640ee8388799ff495cf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "102703cf296d47368bd363184fa8c114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c183b4120d6446c48f627eb1ac5a1bfc",
              "IPY_MODEL_5b841a3531744515b0006f832f0a1b4e",
              "IPY_MODEL_832af0bd97e14215a081efcdd44e4d8d"
            ],
            "layout": "IPY_MODEL_80a950bab2ae44ea868d546ab2bcfd39"
          }
        },
        "c183b4120d6446c48f627eb1ac5a1bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aca9b61c5e48482abfe86b3b76da1128",
            "placeholder": "​",
            "style": "IPY_MODEL_25e87e1e7f3646f2a70e109d296a69e7",
            "value": "Map: 100%"
          }
        },
        "5b841a3531744515b0006f832f0a1b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52da043ae654ea4a9a66772dadfdc9d",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd75bdebc70646e2a3ff0f5374dd3fae",
            "value": 500
          }
        },
        "832af0bd97e14215a081efcdd44e4d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fee95b4aae344ebbe26e6b1a71712c5",
            "placeholder": "​",
            "style": "IPY_MODEL_b4e95e63e66f4369a78d838a050eae51",
            "value": " 500/500 [00:00&lt;00:00, 5685.57 examples/s]"
          }
        },
        "80a950bab2ae44ea868d546ab2bcfd39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aca9b61c5e48482abfe86b3b76da1128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e87e1e7f3646f2a70e109d296a69e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f52da043ae654ea4a9a66772dadfdc9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd75bdebc70646e2a3ff0f5374dd3fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fee95b4aae344ebbe26e6b1a71712c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e95e63e66f4369a78d838a050eae51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0b1680927f44084a8b2c4cff8c3f240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fe9ecbb8ab640a2a69a735147b7592c",
              "IPY_MODEL_6f94ce433fb747bcb26ae64f62a288b6",
              "IPY_MODEL_876227fd79d64aa2a1d5da08878b6803"
            ],
            "layout": "IPY_MODEL_60c0e6bb77ab414d890c4d46c0ff5e91"
          }
        },
        "9fe9ecbb8ab640a2a69a735147b7592c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b168cec6103a4031afbc4345225ebb0e",
            "placeholder": "​",
            "style": "IPY_MODEL_e1cb09a6df274179adcd2d7cac55c32a",
            "value": "Map: 100%"
          }
        },
        "6f94ce433fb747bcb26ae64f62a288b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb17db9557b24f55b78a6431f2ecd157",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03d30b68a0e74db1952300feaeeb345e",
            "value": 500
          }
        },
        "876227fd79d64aa2a1d5da08878b6803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af3144822f68466cbcc47fe9d2c668b5",
            "placeholder": "​",
            "style": "IPY_MODEL_d7c9f1b92bff4f44863b6faddba0e355",
            "value": " 500/500 [00:00&lt;00:00, 1442.14 examples/s]"
          }
        },
        "60c0e6bb77ab414d890c4d46c0ff5e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b168cec6103a4031afbc4345225ebb0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1cb09a6df274179adcd2d7cac55c32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb17db9557b24f55b78a6431f2ecd157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03d30b68a0e74db1952300feaeeb345e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af3144822f68466cbcc47fe9d2c668b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7c9f1b92bff4f44863b6faddba0e355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0256c52c914c47c3b85459ed5dfa8525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33b290ecba3c496787ec60117f0d44eb",
              "IPY_MODEL_d055b8d0f98541ae9fa2c6badbd1cd44",
              "IPY_MODEL_025b4ec64edd4d1eb0e3ab3e92ca2288"
            ],
            "layout": "IPY_MODEL_aa1906a6271e451084c5ee23a9386d99"
          }
        },
        "33b290ecba3c496787ec60117f0d44eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34375b59df474fd88ec9ccd795c44cbb",
            "placeholder": "​",
            "style": "IPY_MODEL_3c1e71a33f6d420aa5f71945f602768c",
            "value": "Filter: 100%"
          }
        },
        "d055b8d0f98541ae9fa2c6badbd1cd44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb9420136f0440fc972f3f02874a4c06",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_395111b37e344021b92a86c6310a21bc",
            "value": 500
          }
        },
        "025b4ec64edd4d1eb0e3ab3e92ca2288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e364bf907e99440f9505856200fdc1fc",
            "placeholder": "​",
            "style": "IPY_MODEL_4df1101f20404d748eefb34357c00eea",
            "value": " 500/500 [00:00&lt;00:00, 3126.22 examples/s]"
          }
        },
        "aa1906a6271e451084c5ee23a9386d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34375b59df474fd88ec9ccd795c44cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1e71a33f6d420aa5f71945f602768c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb9420136f0440fc972f3f02874a4c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "395111b37e344021b92a86c6310a21bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e364bf907e99440f9505856200fdc1fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df1101f20404d748eefb34357c00eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e71fad7b3c244bdbad476a1682370df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96dea6f7ddb6423db27d4f2a5a01ed07",
              "IPY_MODEL_44bb55d543074aa293b2608f3c9b81c2",
              "IPY_MODEL_6fa1286cd23e47f2bc96dde9675a898b"
            ],
            "layout": "IPY_MODEL_00510a27c1de4eb6bd43b8c68ad1a171"
          }
        },
        "96dea6f7ddb6423db27d4f2a5a01ed07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85e1355703e44aeda70165fb2ac72933",
            "placeholder": "​",
            "style": "IPY_MODEL_fcdc12bb288e4ba7988e96341d5ef869",
            "value": "Truncating train dataset: 100%"
          }
        },
        "44bb55d543074aa293b2608f3c9b81c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9236839a6e6946ff96d1635a7759595b",
            "max": 12460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b575571786e947419cc56d28f6641c71",
            "value": 12460
          }
        },
        "6fa1286cd23e47f2bc96dde9675a898b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6edbeee8df7e408191c40345354f84f4",
            "placeholder": "​",
            "style": "IPY_MODEL_684b2c26ef12460a849bfa171726ff2c",
            "value": " 12460/12460 [00:00&lt;00:00, 41664.58 examples/s]"
          }
        },
        "00510a27c1de4eb6bd43b8c68ad1a171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e1355703e44aeda70165fb2ac72933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcdc12bb288e4ba7988e96341d5ef869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9236839a6e6946ff96d1635a7759595b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b575571786e947419cc56d28f6641c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6edbeee8df7e408191c40345354f84f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684b2c26ef12460a849bfa171726ff2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75e04422412f4d16afe8b4873c9006f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6afa8be058a24a79927363e2caf9ea61",
              "IPY_MODEL_34ba865dcb7a4a3ab967dc2d1ae44600",
              "IPY_MODEL_5dca6fc55285466ab212a5be5850f90f"
            ],
            "layout": "IPY_MODEL_229ed1f1851340ea9dc23c6c790dd29f"
          }
        },
        "6afa8be058a24a79927363e2caf9ea61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bf13a2fa81b42d6a04c5d64a477de78",
            "placeholder": "​",
            "style": "IPY_MODEL_80f6601b260f4921a18a1c182aec4027",
            "value": "Truncating eval dataset: 100%"
          }
        },
        "34ba865dcb7a4a3ab967dc2d1ae44600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d67816c9d6e3481d97a9e6e696ea064f",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6917bc9da67b4550a848e2c6435cfa87",
            "value": 500
          }
        },
        "5dca6fc55285466ab212a5be5850f90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6d0b0fa76c341688593b6b56067879e",
            "placeholder": "​",
            "style": "IPY_MODEL_4584beaf5b26406ba8d32b006a9b039d",
            "value": " 500/500 [00:00&lt;00:00, 14881.44 examples/s]"
          }
        },
        "229ed1f1851340ea9dc23c6c790dd29f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf13a2fa81b42d6a04c5d64a477de78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f6601b260f4921a18a1c182aec4027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d67816c9d6e3481d97a9e6e696ea064f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6917bc9da67b4550a848e2c6435cfa87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6d0b0fa76c341688593b6b56067879e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4584beaf5b26406ba8d32b006a9b039d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}